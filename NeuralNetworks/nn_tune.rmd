---
title: "NN tuning"
output: html_document
---
Neural network model needs careful calibration because it is prone to overfitting. In this demonstration combination of regularization parameter and number of neurons in 1 hidden-layer model will be analysed to identify the best performing model on the test set.

```{r, data.import}
suppressPackageStartupMessages(library(dplyr))
file <- "C:/Users/user/Disk Google/Disertace/Analysis/Survival/Data/final_data.txt"
data.in <- read.table(file, sep=";", header=TRUE)
train.data <- data.in %>% filter(year==2011)
test.data <- data.in %>% filter(year==2012)
```

Packages `nnet` and `caret` will be used.

```{r, libraries}
library(nnet)
suppressPackageStartupMessages(library(caret))
```
Configure standard nnet model: 
```{r, standard}
set.seed(1234) # for reproducibility
fit1 <- nnet(as.factor(def) ~ acid.test + debt.ratio + asset.turn + returns, size = 4, data=train.data)
```

And now via 'caret::train' function.
```{r, train.fun}
fit2 <- train(as.factor(def) ~ acid.test + debt.ratio + asset.turn + returns,
              data = train.data, method="nnet", trace=FALSE, 
              tuneGrid=expand.grid(.size=2:5, .decay=c(0, 0.1, 0.15, 0.2, 0.25, 0.3, 0.5)))
```

Inspect the results:
```{r, plot_tune}
plot(fit2)
```

And textual:
```{r, tune_textual}
summary(fit2)
```

Initial model was tuned to achieve highest accuracy. Now, cost matrix will be imposed.
```{r, cost.define}
my.cost <- function(predicted, observed){
 temp <- paste0(predicted, observed)
 total.cost <- ifelse(temp == "11", 15, #15
  ifelse(temp == "10", -20,  #-20
   ifelse(temp == "01", -5, 5) # -5, 5
  )
 )
sum(total.cost)
}
```
'caret' requires function which is passed into 'train' summary function:
```{r, summary.fun}
cost.fun <- function(data, lev=c("0","1"), model="nnet"){
   out <- c(postResample(data[ ,"pred"], data[ ,"obs"]), # built-in statistics (Accuracy, Kappa)
    total.cost = my.cost(data[ ,"pred"], data[ ,"obs"]) )
   out
  }
```

Define new model with adjusted settings:
```{r, new.model}
control.nnet <- trainControl(summaryFunction=cost.fun)

fit3 <- train(as.factor(def) ~ acid.test + debt.ratio + asset.turn + returns,
              data = train.data, method="nnet", trace=FALSE, 
              tuneGrid=expand.grid(.size=2:5, .decay=c(0, 0.1, 0.15, 0.2, 0.25, 0.3, 0.5)),
              trControl = control.nnet,
              metric = "total.cost", maximize=TRUE)
```

And visual results:
```{r, visual_cost}
plot(fit3)
```

Graphical outcome:
```{r, graphical_summary}
fit3
```

Make prediction on the best model:
```{r, prediction.tab}
fit4 <- nnet(as.factor(def) ~ acid.test + debt.ratio + asset.turn + returns, 
             size = 3, decay=0.1, data=train.data,
             trControl = control.nnet,
             metric = "total.cost", maximize=TRUE)

yhat <- data.frame(
 real = test.data$def,
 predicted = predict(fit4, newdata=test.data, type="class"),
 raw = predict(fit4, newdata=test.data, type="raw") )

table(yhat$real, yhat$predicted)
```



